{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P5jTksBBsOpw"
      },
      "source": [
        "#### **Dataset Preparation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xQmuZMvcAbsI",
        "outputId": "fdd7be85-df40-4f1a-f387-7838d644b222"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.25.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.67.1)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.1)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.5.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "tquEGEkhEHwi"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import pickle\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dropout, Dense\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, Callback"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "45i6J9J7B2eA"
      },
      "outputs": [],
      "source": [
        "# Loading the dataset\n",
        "poetry_df = pd.read_csv('PoetryFoundationData.csv', nrows=1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "ibH8f6c3HeGo",
        "outputId": "1b125baa-def1-473a-c9c1-ac0909b5db2f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0                                              Title  \\\n",
              "0           0  \\r\\r\\n                    Objects Used to Prop...   \n",
              "1           1  \\r\\r\\n                    The New Church\\r\\r\\n...   \n",
              "2           2  \\r\\r\\n                    Look for Me\\r\\r\\n   ...   \n",
              "3           3  \\r\\r\\n                    Wild Life\\r\\r\\n     ...   \n",
              "4           4  \\r\\r\\n                    Umbrella\\r\\r\\n      ...   \n",
              "\n",
              "                                                Poem              Poet Tags  \n",
              "0  \\r\\r\\nDog bone, stapler,\\r\\r\\ncribbage board, ...  Michelle Menting  NaN  \n",
              "1  \\r\\r\\nThe old cupola glinted above the clouds,...     Lucia Cherciu  NaN  \n",
              "2  \\r\\r\\nLook for me under the hood\\r\\r\\nof that ...        Ted Kooser  NaN  \n",
              "3  \\r\\r\\nBehind the silo, the Mother Rabbit\\r\\r\\n...   Grace Cavalieri  NaN  \n",
              "4  \\r\\r\\nWhen I push your button\\r\\r\\nyou fly off...      Connie Wanek  NaN  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-eef509e7-e63b-4113-af72-25fba7b5694c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Title</th>\n",
              "      <th>Poem</th>\n",
              "      <th>Poet</th>\n",
              "      <th>Tags</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>\\r\\r\\n                    Objects Used to Prop...</td>\n",
              "      <td>\\r\\r\\nDog bone, stapler,\\r\\r\\ncribbage board, ...</td>\n",
              "      <td>Michelle Menting</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>\\r\\r\\n                    The New Church\\r\\r\\n...</td>\n",
              "      <td>\\r\\r\\nThe old cupola glinted above the clouds,...</td>\n",
              "      <td>Lucia Cherciu</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>\\r\\r\\n                    Look for Me\\r\\r\\n   ...</td>\n",
              "      <td>\\r\\r\\nLook for me under the hood\\r\\r\\nof that ...</td>\n",
              "      <td>Ted Kooser</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>\\r\\r\\n                    Wild Life\\r\\r\\n     ...</td>\n",
              "      <td>\\r\\r\\nBehind the silo, the Mother Rabbit\\r\\r\\n...</td>\n",
              "      <td>Grace Cavalieri</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>\\r\\r\\n                    Umbrella\\r\\r\\n      ...</td>\n",
              "      <td>\\r\\r\\nWhen I push your button\\r\\r\\nyou fly off...</td>\n",
              "      <td>Connie Wanek</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-eef509e7-e63b-4113-af72-25fba7b5694c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-eef509e7-e63b-4113-af72-25fba7b5694c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-eef509e7-e63b-4113-af72-25fba7b5694c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-07849687-8a24-4e79-a3fb-7bc6396e88a5\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-07849687-8a24-4e79-a3fb-7bc6396e88a5')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-07849687-8a24-4e79-a3fb-7bc6396e88a5 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "poetry_df",
              "summary": "{\n  \"name\": \"poetry_df\",\n  \"rows\": 1000,\n  \"fields\": [\n    {\n      \"column\": \"Unnamed: 0\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 55,\n        \"min\": 0,\n        \"max\": 197,\n        \"num_unique_values\": 198,\n        \"samples\": [\n          65,\n          114,\n          16\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 994,\n        \"samples\": [\n          \"\\r\\r\\n                    Jealousy\\r\\r\\n                \",\n          \"\\r\\r\\n                    Dear Proofreader\\r\\r\\n                \",\n          \"\\r\\r\\n                    The Leash\\r\\r\\n                \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Poem\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 999,\n        \"samples\": [\n          \"\\r\\r\\nNow begins the festival and rivalry of late fall,\\r\\r\\nthe weird debauch and daring debacle\\r\\r\\nof frat-boy parties as students parade foggy streets in mock\\r\\r\\nprocessions, bearing on shoulders scrawny effigies of dead,\\r\\r\\ndefeated Indians cut from trees, where,\\r\\r\\nin the twilight, they had earlier been hung.\\r\\r\\n \\r\\r\\n\\\"Just dummies,\\\" laughs our dad, \\\"Red Indians hung\\r\\r\\nor burned\\u2014it's only in jest.\\\" Every fall\\r\\r\\nbrings the Big Game against Stanford, where\\r\\r\\nyoung scholars let off steam before the debacle\\r\\r\\nthey may face of failed exams. \\\"You're dead\\r\\r\\nwrong,\\\" he says to Mom. \\\"They don't mock\\r\\r\\n \\r\\r\\nreal, live Indians.\\\" Around UC campus, mock\\r\\r\\nlynchings go on. Beneath porches we see hung\\r\\r\\nthe scarecrow Natives with fake long braids, dead\\r\\r\\nfrom the merrymaking. On Bancroft Way, one has fallen\\r\\r\\nindecorously to a lawn, a symbol of the debacle\\r\\r\\nthat happened three generations ago in California's hills, where\\r\\r\\n \\r\\r\\nNative peoples were strung up. (A way of having fun? Where\\r\\r\\ndid they go, those Indian ghosts?) \\\"Their kids perform mock\\r\\r\\nwar dances, whooping, re-enacting scenes of a debacle\\r\\r\\nwhite folks let loose,\\\" chides Mom. \\\"Meanwhile we hang\\r\\r\\nportraits of presidents on school walls and never let fall\\r\\r\\nthe old red, white, and blue. My dear brother is dead\\r\\r\\n \\r\\r\\nbecause he fought in a White man's war. How many dead\\r\\r\\nIndians do they need to feel okay? This whole thing wears\\r\\r\\non my soul.\\\" In the dark car we go silent, and the fall\\r\\r\\nnight gets chillier. In yards, blazing bonfires mock\\r\\r\\nthe stars that glow palely somewhere above. A thin moon hangs\\r\\r\\nover the tule fogs. I've never heard the word \\\"debacle\\u201d\\r\\r\\n \\r\\r\\nbefore and wonder what it means. \\\"What's a debacle,\\r\\r\\nMom? \\\" I ask. \\\"Oh, honey, it's a terrible and deadly\\r\\r\\ncollapse. Complete ruin.\\\" I've noticed how the hung\\r\\r\\nIndians have their heads slumped forward. They wear\\r\\r\\nold clothes, headbands with feathers, face paint, moc-\\r\\r\\ncasins instead of boots. Little do we know, this fall,\\r\\r\\n \\r\\r\\nliving Indians at Feather Falls\\r\\r\\nleave tobacco to mark that, indeed,\\r\\r\\nwe're still here, lungs full of indigenous air.\\r\\r\\n\",\n          \"\\r\\r\\nof waves dropped into froth     Jellyfish a jar\\r\\r\\nof innards half-buried in sand     Dead nature     What are\\r\\r\\nthese things and who are they for?     This blue rug\\r\\r\\nis its own genre     And these painted apples\\r\\r\\nround out the essence of what can be made\\r\\r\\ninto what can be eaten     Winter interest\\r\\r\\n3.9 APR     April come     She will not\\r\\r\\nswipe the sun into sky     Limits of credentialed\\r\\r\\ncredit     \\u201cAt least you\\u2019re not the janitor\\u2019s\\r\\r\\nazaleas of the everyday dustpan\\u201d     There\\u2019s\\r\\r\\nthe problem     It\\u2019s like a concussive\\r\\r\\ngrenade at the end of the mine     Mind the\\r\\r\\nincome gap     Let\\u2019s activate the fact that\\r\\r\\nevery word means go back to the back of the line\\r\\r\\nbecause that is where the front leads     Years\\r\\r\\nof the postmodern translated by the annuity\\r\\r\\nof spring     Hello     My name\\r\\r\\nis the first person I     I am indebted     I am\\r\\r\\nindented     I insist on remaining\\r\\r\\nunidentified\\r\\r\\n \\r\\r\\n\",\n          \"\\r\\r\\nI wore Grandma Liz's pearls\\r\\r\\nfor play, a plastic strand long\\r\\r\\nenough to pool on the carpet\\r\\r\\nover my stubbed toes. When I pull\\r\\r\\nthem over my head now, I smell\\r\\r\\nphantoms: cigarettes, Este\\u00e9\\r\\r\\nLauder. I don't smoke or spritz\\r\\r\\non perfume. I don't layer polyester\\r\\r\\nor perm my hair. I've slipped off\\r\\r\\nmy wedding ring as she did, signed\\r\\r\\ndivorce. What advice would she offer\\r\\r\\nfor life between husbands? Wear redlipstick and always leave it behind.\\r\\r\\n \\r\\r\\n\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Poet\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 429,\n        \"samples\": [\n          \"Betsy Franco\",\n          \"Vincent Katz\",\n          \"Ruben Quesada\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Tags\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 715,\n        \"samples\": [\n          \"Language & Linguistics\",\n          \"Activities,Jobs & Working,Religion,Christianity\",\n          \"Landscapes & Pastorals,Money & Economics\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "poetry_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Juos6xdcHuTu",
        "outputId": "21899a57-8b7f-4a01-9f31-7508e48add44"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "poetry_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cleaning data\n",
        "poetry_df['Poem'] = poetry_df['Poem'].str.replace(r'\\s+', ' ', regex=True)\n",
        "poetry_df['Title'] = poetry_df['Title'].str.replace(r'\\s+', ' ', regex=True)\n",
        "poetry_df['input'] = poetry_df['Title'] + ' *** ' + poetry_df['Poem']"
      ],
      "metadata": {
        "id": "hBet2hLFfilQ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Exploring the columns\n",
        "print(poetry_df.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "10ikd1uYfzKO",
        "outputId": "70adccd7-0da2-4e05-ca21-dc00943cfc06"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['Unnamed: 0', 'Title', 'Poem', 'Poet', 'Tags', 'input'], dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_data = poetry_df['input'].values.tolist()\n",
        "\n",
        "# Printing a portion of the corpus to verify\n",
        "print(input_data[:3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "glyC-b17fzNl",
        "outputId": "86828bc5-5669-4e32-d667-297929d2d986"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\" Objects Used to Prop Open a Window  ***  Dog bone, stapler, cribbage board, garlic press because this window is loose—lacks suction, lacks grip. Bungee cord, bootstrap, dog leash, leather belt because this window had sash cords. They frayed. They broke. Feather duster, thatch of straw, empty bottle of Elmer's glue because this window is loud—its hinges clack open, clack shut. Stuffed bear, baby blanket, single crib newel because this window is split. It's dividing in two. Velvet moss, sagebrush, willow branch, robin's wing because this window, it's pane-less. It's only a frame of air. \", ' The New Church  ***  The old cupola glinted above the clouds, shone among fir trees, but it took him an hour for the half mile all the way up the hill. As he trailed, the village passed him by, greeted him, asked about his health, but everybody hurried to catch the mass, left him leaning against fences, measuring the road with the walking stick he sculpted. He yearned for the day when the new church would be built—right across the road. Now it rises above the moon: saints in frescoes meet the eye, and only the rain has started to cut through the shingles on the roof of his empty house. The apple trees have taken over the sky, sequestered the gate, sidled over the porch. ', \" Look for Me  ***  Look for me under the hood of that old Chevrolet settled in weeds at the end of the pasture. I'm the radiator that spent its years bolted in front of an engine shoving me forward into the wind. Whatever was in me in those days has mostly leaked away, but my cap's still screwed on tight and I know the names of all these tattered moths and broken grasshoppers the rest of you've forgotten. \"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Data Preprocessing**"
      ],
      "metadata": {
        "id": "8i14YmcvgiJ2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "iQ8ObHAEBq5o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45ec5196-7c0c-4539-d445-a872f7709a7a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "30216\n"
          ]
        }
      ],
      "source": [
        "# Tokenizing the text (conversion of each word to a unique integer)\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(input_data)\n",
        "total_words = len(tokenizer.word_index) + 1\n",
        "\n",
        "print(total_words)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating input sequences using sequences of words\n",
        "input_sequences = []\n",
        "for line in input_data:\n",
        "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
        "    for i in range(1, min(len(token_list), 50)):  # Cap sequence length to 50\n",
        "        n_gram_sequence = token_list[:i+1]\n",
        "        input_sequences.append(n_gram_sequence)\n",
        "\n",
        "# Calculating max_sequence_len\n",
        "max_sequence_len = max(len(seq) for seq in input_sequences)\n",
        "\n",
        "# Padding sequences and creating predictors and labels\n",
        "input_sequences = pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre')\n",
        "predictors, label = input_sequences[:, :-1], input_sequences[:, -1]\n",
        "label = to_categorical(label, num_classes=total_words)"
      ],
      "metadata": {
        "id": "fEa9Tl8qgmqB"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining the batch size\n",
        "batch_size = 32\n",
        "\n",
        "# Generator function to yield batches of data\n",
        "def data_generator(predictors, labels):\n",
        "    dataset_size = len(predictors)\n",
        "    indices = np.arange(dataset_size)\n",
        "    np.random.shuffle(indices)\n",
        "    for idx in indices:\n",
        "        yield predictors[idx], labels[idx]"
      ],
      "metadata": {
        "id": "IxvFvbQNg1Ij"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a TensorFlow Dataset from the generator function\n",
        "dataset = tf.data.Dataset.from_generator(\n",
        "    lambda: data_generator(predictors, label),\n",
        "    output_signature=(\n",
        "        tf.TensorSpec(shape=(predictors.shape[1],), dtype=tf.int32),\n",
        "        tf.TensorSpec(shape=(label.shape[1],), dtype=tf.float32)\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "id": "nwvp_5ffg3SY"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Shuffling and batching the dataset\n",
        "dataset = dataset.shuffle(buffer_size=10000).batch(batch_size).repeat()\n",
        "\n",
        "# Splitting the dataset into training and validation sets\n",
        "train_size = 100000\n",
        "val_size = 20000\n",
        "\n",
        "train_dataset = dataset.take(train_size // batch_size)\n",
        "val_dataset = dataset.skip(train_size // batch_size).take(val_size // batch_size)"
      ],
      "metadata": {
        "id": "hwKEkSLGg3U8"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining the ModelCheckpoint callback\n",
        "checkpoint_path = \"model_checkpoint.keras\"\n",
        "checkpoint_callback = ModelCheckpoint(filepath=checkpoint_path,\n",
        "                                      monitor='val_loss',\n",
        "                                      save_best_only=True,\n",
        "                                      mode='min',\n",
        "                                      verbose=1)\n",
        "\n",
        "# Defining EarlyStopping callback\n",
        "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=3, verbose=1)"
      ],
      "metadata": {
        "id": "JRpr5uzkg3Yk"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **LSTM Model Development**"
      ],
      "metadata": {
        "id": "sIrOvZ2hhc3V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Building the model\n",
        "def create_model():\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(total_words, 50))\n",
        "    model.add(LSTM(100))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(total_words, activation='softmax'))\n",
        "    return model\n",
        "\n",
        "model = create_model()\n",
        "model.build(input_shape=(None, max_sequence_len))\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "rUI5ay5ShcGm",
        "outputId": "31bc7650-a087-4dcb-c991-739db82461b8"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m)              │       \u001b[38;5;34m1,510,800\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)                 │          \u001b[38;5;34m60,400\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30216\u001b[0m)               │       \u001b[38;5;34m3,051,816\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)              │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,510,800</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">60,400</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30216</span>)               │       <span style=\"color: #00af00; text-decoration-color: #00af00\">3,051,816</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,623,016\u001b[0m (17.64 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,623,016</span> (17.64 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,623,016\u001b[0m (17.64 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,623,016</span> (17.64 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Training the Model**"
      ],
      "metadata": {
        "id": "goMYScBph_Ha"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the model with batching\n",
        "history = model.fit(train_dataset,\n",
        "                    epochs=30,\n",
        "                    verbose=1,\n",
        "                    validation_data=val_dataset,\n",
        "                    callbacks=[early_stopping_callback, checkpoint_callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LZxnKbBHhNdr",
        "outputId": "af45c0b6-d107-49a5-89ee-869c7bff6414"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - accuracy: 0.0623 - loss: 7.7097\n",
            "Epoch 1: val_loss improved from inf to 6.77108, saving model to model_checkpoint.keras\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m416s\u001b[0m 131ms/step - accuracy: 0.0623 - loss: 7.7096 - val_accuracy: 0.0767 - val_loss: 6.7711\n",
            "Epoch 2/30\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - accuracy: 0.0772 - loss: 6.7470\n",
            "Epoch 2: val_loss improved from 6.77108 to 6.16529, saving model to model_checkpoint.keras\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m411s\u001b[0m 130ms/step - accuracy: 0.0772 - loss: 6.7470 - val_accuracy: 0.0988 - val_loss: 6.1653\n",
            "Epoch 3/30\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - accuracy: 0.0960 - loss: 6.2414\n",
            "Epoch 3: val_loss improved from 6.16529 to 5.56188, saving model to model_checkpoint.keras\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m444s\u001b[0m 131ms/step - accuracy: 0.0960 - loss: 6.2414 - val_accuracy: 0.1186 - val_loss: 5.5619\n",
            "Epoch 4/30\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - accuracy: 0.1156 - loss: 5.6865\n",
            "Epoch 4: val_loss improved from 5.56188 to 4.92895, saving model to model_checkpoint.keras\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m426s\u001b[0m 135ms/step - accuracy: 0.1156 - loss: 5.6865 - val_accuracy: 0.1656 - val_loss: 4.9290\n",
            "Epoch 5/30\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - accuracy: 0.1434 - loss: 5.1397\n",
            "Epoch 5: val_loss improved from 4.92895 to 4.33299, saving model to model_checkpoint.keras\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m394s\u001b[0m 125ms/step - accuracy: 0.1434 - loss: 5.1397 - val_accuracy: 0.2343 - val_loss: 4.3330\n",
            "Epoch 6/30\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - accuracy: 0.1943 - loss: 4.5920\n",
            "Epoch 6: val_loss improved from 4.33299 to 3.75983, saving model to model_checkpoint.keras\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m394s\u001b[0m 125ms/step - accuracy: 0.1943 - loss: 4.5920 - val_accuracy: 0.3173 - val_loss: 3.7598\n",
            "Epoch 7/30\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - accuracy: 0.2538 - loss: 4.0851\n",
            "Epoch 7: val_loss improved from 3.75983 to 3.26902, saving model to model_checkpoint.keras\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m444s\u001b[0m 126ms/step - accuracy: 0.2538 - loss: 4.0851 - val_accuracy: 0.3880 - val_loss: 3.2690\n",
            "Epoch 8/30\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - accuracy: 0.3184 - loss: 3.6213\n",
            "Epoch 8: val_loss improved from 3.26902 to 2.82398, saving model to model_checkpoint.keras\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m419s\u001b[0m 133ms/step - accuracy: 0.3184 - loss: 3.6213 - val_accuracy: 0.4699 - val_loss: 2.8240\n",
            "Epoch 9/30\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - accuracy: 0.3842 - loss: 3.2116\n",
            "Epoch 9: val_loss improved from 2.82398 to 2.44069, saving model to model_checkpoint.keras\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m416s\u001b[0m 124ms/step - accuracy: 0.3842 - loss: 3.2116 - val_accuracy: 0.5404 - val_loss: 2.4407\n",
            "Epoch 10/30\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - accuracy: 0.4370 - loss: 2.8702\n",
            "Epoch 10: val_loss improved from 2.44069 to 2.13088, saving model to model_checkpoint.keras\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m394s\u001b[0m 125ms/step - accuracy: 0.4370 - loss: 2.8702 - val_accuracy: 0.5873 - val_loss: 2.1309\n",
            "Epoch 11/30\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - accuracy: 0.4867 - loss: 2.5576\n",
            "Epoch 11: val_loss improved from 2.13088 to 1.87605, saving model to model_checkpoint.keras\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m441s\u001b[0m 125ms/step - accuracy: 0.4867 - loss: 2.5576 - val_accuracy: 0.6334 - val_loss: 1.8761\n",
            "Epoch 12/30\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - accuracy: 0.5268 - loss: 2.3144\n",
            "Epoch 12: val_loss improved from 1.87605 to 1.64608, saving model to model_checkpoint.keras\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m443s\u001b[0m 125ms/step - accuracy: 0.5268 - loss: 2.3144 - val_accuracy: 0.6800 - val_loss: 1.6461\n",
            "Epoch 13/30\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - accuracy: 0.5645 - loss: 2.0944\n",
            "Epoch 13: val_loss improved from 1.64608 to 1.45092, saving model to model_checkpoint.keras\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m439s\u001b[0m 124ms/step - accuracy: 0.5645 - loss: 2.0944 - val_accuracy: 0.7193 - val_loss: 1.4509\n",
            "Epoch 14/30\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - accuracy: 0.5963 - loss: 1.9120\n",
            "Epoch 14: val_loss improved from 1.45092 to 1.28497, saving model to model_checkpoint.keras\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m397s\u001b[0m 126ms/step - accuracy: 0.5963 - loss: 1.9120 - val_accuracy: 0.7476 - val_loss: 1.2850\n",
            "Epoch 15/30\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - accuracy: 0.6244 - loss: 1.7585\n",
            "Epoch 15: val_loss improved from 1.28497 to 1.15680, saving model to model_checkpoint.keras\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m443s\u001b[0m 126ms/step - accuracy: 0.6244 - loss: 1.7585 - val_accuracy: 0.7708 - val_loss: 1.1568\n",
            "Epoch 16/30\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - accuracy: 0.6465 - loss: 1.6375\n",
            "Epoch 16: val_loss improved from 1.15680 to 1.04440, saving model to model_checkpoint.keras\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m421s\u001b[0m 134ms/step - accuracy: 0.6465 - loss: 1.6375 - val_accuracy: 0.7925 - val_loss: 1.0444\n",
            "Epoch 17/30\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - accuracy: 0.6684 - loss: 1.5112\n",
            "Epoch 17: val_loss improved from 1.04440 to 0.94393, saving model to model_checkpoint.keras\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m413s\u001b[0m 124ms/step - accuracy: 0.6684 - loss: 1.5112 - val_accuracy: 0.8148 - val_loss: 0.9439\n",
            "Epoch 18/30\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - accuracy: 0.6880 - loss: 1.4042\n",
            "Epoch 18: val_loss improved from 0.94393 to 0.86349, saving model to model_checkpoint.keras\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m448s\u001b[0m 126ms/step - accuracy: 0.6880 - loss: 1.4042 - val_accuracy: 0.8328 - val_loss: 0.8635\n",
            "Epoch 19/30\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - accuracy: 0.7037 - loss: 1.3176\n",
            "Epoch 19: val_loss improved from 0.86349 to 0.77170, saving model to model_checkpoint.keras\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m398s\u001b[0m 126ms/step - accuracy: 0.7037 - loss: 1.3176 - val_accuracy: 0.8492 - val_loss: 0.7717\n",
            "Epoch 20/30\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - accuracy: 0.7200 - loss: 1.2385\n",
            "Epoch 20: val_loss improved from 0.77170 to 0.69141, saving model to model_checkpoint.keras\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m397s\u001b[0m 126ms/step - accuracy: 0.7200 - loss: 1.2385 - val_accuracy: 0.8707 - val_loss: 0.6914\n",
            "Epoch 21/30\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - accuracy: 0.7340 - loss: 1.1605\n",
            "Epoch 21: val_loss improved from 0.69141 to 0.65611, saving model to model_checkpoint.keras\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m436s\u001b[0m 124ms/step - accuracy: 0.7340 - loss: 1.1605 - val_accuracy: 0.8741 - val_loss: 0.6561\n",
            "Epoch 22/30\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - accuracy: 0.7442 - loss: 1.1054\n",
            "Epoch 22: val_loss improved from 0.65611 to 0.59555, saving model to model_checkpoint.keras\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m396s\u001b[0m 125ms/step - accuracy: 0.7441 - loss: 1.1054 - val_accuracy: 0.8881 - val_loss: 0.5955\n",
            "Epoch 23/30\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - accuracy: 0.7499 - loss: 1.0664\n",
            "Epoch 23: val_loss improved from 0.59555 to 0.55766, saving model to model_checkpoint.keras\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m442s\u001b[0m 125ms/step - accuracy: 0.7499 - loss: 1.0664 - val_accuracy: 0.8939 - val_loss: 0.5577\n",
            "Epoch 24/30\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - accuracy: 0.7629 - loss: 1.0049\n",
            "Epoch 24: val_loss improved from 0.55766 to 0.51933, saving model to model_checkpoint.keras\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m396s\u001b[0m 126ms/step - accuracy: 0.7629 - loss: 1.0049 - val_accuracy: 0.9001 - val_loss: 0.5193\n",
            "Epoch 25/30\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - accuracy: 0.7723 - loss: 0.9544\n",
            "Epoch 25: val_loss improved from 0.51933 to 0.47557, saving model to model_checkpoint.keras\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m433s\u001b[0m 123ms/step - accuracy: 0.7723 - loss: 0.9544 - val_accuracy: 0.9103 - val_loss: 0.4756\n",
            "Epoch 26/30\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - accuracy: 0.7790 - loss: 0.9228\n",
            "Epoch 26: val_loss improved from 0.47557 to 0.44837, saving model to model_checkpoint.keras\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m412s\u001b[0m 131ms/step - accuracy: 0.7790 - loss: 0.9228 - val_accuracy: 0.9152 - val_loss: 0.4484\n",
            "Epoch 27/30\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - accuracy: 0.7907 - loss: 0.8800\n",
            "Epoch 27: val_loss improved from 0.44837 to 0.41841, saving model to model_checkpoint.keras\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m416s\u001b[0m 122ms/step - accuracy: 0.7907 - loss: 0.8800 - val_accuracy: 0.9231 - val_loss: 0.4184\n",
            "Epoch 28/30\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - accuracy: 0.7955 - loss: 0.8432\n",
            "Epoch 28: val_loss improved from 0.41841 to 0.40181, saving model to model_checkpoint.keras\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m392s\u001b[0m 125ms/step - accuracy: 0.7955 - loss: 0.8432 - val_accuracy: 0.9254 - val_loss: 0.4018\n",
            "Epoch 29/30\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - accuracy: 0.7990 - loss: 0.8215\n",
            "Epoch 29: val_loss improved from 0.40181 to 0.36802, saving model to model_checkpoint.keras\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m414s\u001b[0m 131ms/step - accuracy: 0.7990 - loss: 0.8215 - val_accuracy: 0.9306 - val_loss: 0.3680\n",
            "Epoch 30/30\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - accuracy: 0.8053 - loss: 0.7914\n",
            "Epoch 30: val_loss improved from 0.36802 to 0.35758, saving model to model_checkpoint.keras\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m417s\u001b[0m 124ms/step - accuracy: 0.8053 - loss: 0.7914 - val_accuracy: 0.9336 - val_loss: 0.3576\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving the model\n",
        "model.save(\"trained_model.h5\")\n",
        "\n",
        "# Loading the trained model\n",
        "model = tf.keras.models.load_model('trained_model.h5')"
      ],
      "metadata": {
        "id": "JUPZihBph3rN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2565f13-a501-4e11-bed4-e10c4c5e8e9d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Text Generation**"
      ],
      "metadata": {
        "id": "dwJcJ9Jhxcxy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_poetry(seed_text, next_words, model, max_sequence_len, tokenizer):\n",
        "    for _ in range(next_words):\n",
        "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "        token_list = pad_sequences([token_list], maxlen=max_sequence_len - 1, padding='pre')\n",
        "        predicted = np.argmax(model.predict(token_list, verbose=0), axis=-1)\n",
        "        output_word = \"\"\n",
        "        for word, index in tokenizer.word_index.items():\n",
        "            if index == predicted:\n",
        "                output_word = word\n",
        "                break\n",
        "        seed_text += \" \" + output_word\n",
        "    return seed_text"
      ],
      "metadata": {
        "id": "Y1M8SaaohNhF"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seed_texts = [\"The moon\", \"Love's embrace\", \"Autumn leaves\"]\n",
        "for seed_text in seed_texts:\n",
        "    generated_poetry = generate_poetry(seed_text, 20, model, max_sequence_len, tokenizer)\n",
        "    print(f\"Generated poetry with seed '{seed_text}':\\n{generated_poetry}\\n\")"
      ],
      "metadata": {
        "id": "clMh1bF0xkO6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ca515c1-6dbd-4fc6-ab26-52dd2c0e9da2"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated poetry with seed 'The moon':\n",
            "The moon at my mother san brother broke up into me when you find a good to all because the sky is\n",
            "\n",
            "Generated poetry with seed 'Love's embrace':\n",
            "Love's embrace heart over the roof top i have imagine which i am thee she says sometimes in them the only knows\n",
            "\n",
            "Generated poetry with seed 'Autumn leaves':\n",
            "Autumn leaves for you i chyll if that ye wyll a whyle be styll of a comely gyll that dwelt on a\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}